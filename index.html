<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta content="IE=edge" http-equiv="X-UA-Compatible">
	<meta content="width=840, initial-scale=1.0" name="viewport">
	<meta content="Ji Zhang" name="author">
	<meta content="Homepage" name="description">

	<style>
	        strong {
	            color: rgb(235, 104, 100);
	        }
			.boxed::after {
				content: "";
				display: block;
				clear: both;
			}
			.projects .boxed img {
				max-width: 100%;
				height: auto;
			}
	    </style>

	<title>Ji Zhang - SWJTU - CS</title>
	<link rel="shortcut icon" href="https://www.ic.gatech.edu/sites/all/themes/coc_sub_theme/favicon.ico" type="image/vnd.microsoft.icon">
	<!-- Bootstrap core CSS -->
	<link href="./files/bootstrap.min.css" rel="stylesheet">
	<!-- Bootstrap theme -->
	<link href="./files/bootstrap-theme.min.css" rel="stylesheet">
	<!-- Bootstrap icon -->
	<link href="./files/bootstrap.icon-large.min.css" rel="stylesheet">
	<!-- Custom styles for this template -->
	<link href="./files/theme.css" rel="stylesheet">
	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<link rel="stylesheet" href="./files/font-awesome.min.css">

	<!--[if lt IE 9]>
	  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
	  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
	<![endif]-->
<script src="chrome-extension://njgehaondchbmjmajphnhlojfnbfokng/js/contentScripts/dom.js"></script></head>

<body>
   <script type="text/javascript" async="" src="./files/ga.js"></script>
	<div class="container-narrow">
		<div class="title">

			<h4><strong>Ji Zhang</strong> &nbsp;&nbsp;&nbsp;&nbsp; 
			
			<img class="img-thumbnail-lizi" height="300" hspace="10" src="./files/JiZhang/jizhang_profile_image.png" style="float:right"> 
	
			</h4>
			Associate Professor<br>
			<a href="https://scai.swjtu.edu.cn/">School of Computing and Artificial Intelligence</a> <br>
			<a href="https://www.swjtu.edu.cn/">Southwest Jiaotong University</a><br>
			<span class="glyphicon glyphicon-envelope"></span>&nbsp; <tt>jizhang@swjtu.edu.cn</tt><br>
			<b>Office: </b>715, Comprehensive Building, Xipu Campus<br>
			<a href="https://scholar.google.com/citations?hl=en&user=F9dKrEwAAAAJ&view_op=list_works&sortby=pubdate">[Google Scholar]</a>

		    <br><br>
		    	<p>I am Ji Zhang (张继), an Assistant Professor in the School of Computing and Artificial Intelligence at Southwest Jiaotong University (SWJTU). I received my Ph.D. degree in 2024 from the School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), where I was very fortunate to be advised by Prof.  <a href="https://scholar.google.com/citations?user=F5Zy9V4AAAAJ&hl=en&oi=ao">Jingkuan Song</a> and Prof. <a href="https://scholar.google.com/citations?user=zsm2dpYAAAAJ&hl=en&oi=ao">Lianli Gao</a>.

		        <p>My research interests include, but are not limited to:</p>
			<ol>
			  <li><strong>Robotics</strong>: Designing advanced algorithms for real-world robotic applications, focusing on robotic foundation models and vision-language-action models (VLAs)</li>
              <li><strong>Computer Vision</strong>: Visual perception, scene understanding, and multimodal perception for embodied systems</li>
              <li><strong>Few-shot Learning</strong>: Efficient learning from limited data, with applications to robotic adaptation and generalization</li>
			</ol>
			<p>If you are also interested in related topics, please do not hesitate to reach out.</p>

			<br>
						
			<img src="./files/recruitment.png" width="20" alt="" style="border-style: none" align="center"> &nbsp; 
			<strong>Open Positions</strong>
			<be>
				<ul>
				  <li>I am recruiting research fellow (holding a doctoral degree) with relevant research experience on Multimedia Contents Analysis and Generative AI. Candidates are expected to have publications in top conferences (NeurIPS, ICLR, ICML, CVPR, ECCV, ICCV, AAAI, ACM-MM, etc.) or high-impact journals (T-PAMI, TIP, TMM,  IJCV, etc.). Qualified candidates are welcome to apply.</li>
	
				  <li>I am looking for 2-3 interns working on Generative AI Security and Embodied AI. Please feel free to email me with your CV if you are interested.</li>
				  <li>Currently, there are no openings for PhD students starting in Fall 2026.</li>
				</ul>
			<br> 
			

		</div>

<div class="navbar navbar-default" role="navigation">
		
   		<div class="container">
        
				<div class="navbar-collapse">
				<ul class="nav navbar-nav">
					<li>
						<a href="https://jingjing1.github.io/#research">Research</a>
					</li>

					<li>
						<a href="https://jingjing1.github.io/#team">Team</a>
					</li>


					<li>
						<a href="https://jingjing1.github.io/#publications">Publications</a>
					</li>


					<li>
						<a href="https://jingjing1.github.io/#teach">Teaching</a>
					</li>


					<li>
						<a href="https://jingjing1.github.io/#publications">Code &amp; Data</a>
					</li>
				</ul>

          
			</div>
		
		</div>
		</div>


		<div class="content">
			<h5 class="text-primary" id="news">What's New</h5>
		         
			<!-- <ul class="news"> -->
			<ul>
				<li style="list-style: none"><br>
				</li>

			<!-- <ul class="news"> -->
			   <li><strong>[Jun 2025]</strong> Our paper about few-shot learning was accepted by TPAMI.</li>
  				<li><strong>[Apr 2025]</strong> I have been invited to be a PC member for NeurIPS'25.</li>
  				<li><strong>[Mar 2025]</strong> I have been invited to be the PC members for ICCV'25 and ACM MM'25.</li>
  				<li><strong>[Feb 2025]</strong> Our paper about vision-language models (VLMs) was accepted by CVPR'25.</li>
				<li><strong>[Nov 2024]</strong> I have been invited to be a PC member for CVPR'25.</li>
				<li><strong>[Aug 2024]</strong> I have been invited to be a PC member for ICLR'25.</li>
				<li><strong>[Feb 2024]</strong> Our paper about vision-language models (VLMs) was accepted by CVPR'24.</li>
				<li><strong>[Oct 2023]</strong> Our paper about out-of-distribution (OOD) detection was accepted by IEEE TIP.</li>
				<li><strong>[Oct 2023]</strong> I'm awarded the "Graduate Chinese National Scholarship".</li>
				<li><strong>[Jul 2023]</strong> Our paper about few-shot learning was accepted by ICCV'23.</li>
				<li><strong>[Apr 2023]</strong> Our paper about few-shot learning was accepted by ICML'23.</li>
				<li><strong>[Jun 2022]</strong> Our papers about few-shot learning and continue learning are accepted by ACM MM'22.</li>
				<li><strong>[Mar 2022]</strong> Our paper about meta-learning was accepted by IEEE TCSVT.</li>
			  	<li><strong>[Jun 2021]</strong> Our paper about meta-learning was accepted by ACM MM'21.</li>
			</ul>		
		</div>




		<div class="content">
			<h5 class="text-primary" id="research">Research Highlights</h5> 
			
			<p>* Equal contribution. # Corresponding author</p>
			<!-- Highlight 1 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://koorye.github.io/proj/Inspire">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjineurips25.png"
			             style="float: right;" width="350px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>*, Shihan Wu*, Xu Luo, Hao Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song<br>
			      arXiv, 2025<br>
			      [<a href="https://arxiv.org/pdf/2505.13888">Paper</a>]
			      [<a href="https://github.com/Koorye/Inspire">Code</a>]
			      [<a href="https://koorye.github.io/proj/Inspire">Project</a>]
			    </p>

			    <p>
			      Mitigating the adverse effects of spurious correlations by boosting the spatial reasoning ability of vision-language-action (VLA) models.
			    </p>
			  </div>
			</div>

			<!-- Highlight 2 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/JimZAI/DETA-plus">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjitpami.png"
			             style="float: left;" width="330px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">Reliable Few-shot Learning under Dual Noises</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>, Jingkuan Song, Lianli Gao, Nicu Sebe, Heng Tao Shen<br>
			      IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025<br>
			      [<a href="https://arxiv.org/abs/2506.16330">Paper</a>]
			      [<a href="https://github.com/JimZAI/DETA-plus">Code</a>]
			    </p>

			    <p>
			      Addressing both ID and OOD noise from support and query samples of few-shot learning tasks within a unified framework.
			    </p>
			  </div>
			</div>

			<!-- Highlight 3 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://arxiv.org/abs/2412.11509">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjicvpr25.png"
			             style="float: right;" width="350px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves</strong></h5>

			    <p>
			      Shihan Wu, <strong>Ji Zhang</strong>#, Pengpeng Zeng, Lianli Gao, Jingkuan Song, Heng Tao Shen<br>
			      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025<br>
			      [<a href="https://arxiv.org/abs/2412.11509">Paper</a>]
			      [<a href="https://github.com/Koorye/SkipTuning">Code</a>]
			    </p>

			    <p>
			      Achieving effective and efficient adaptation of large pre-trained vision-language models.
			    </p>
			  </div>
			</div>

			<!-- Highlight 4 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/Koorye/DePT">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhagnjicvpr.png"
			             style="float: left;" width="330px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">DePT: Decoupled Prompt Tuning</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>*, Shihan Wu*, Lianli Gao, Heng Tao Shen, Jingkuan Song<br>
			      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br>
			      [<a href="https://arxiv.org/abs/2309.07439">Paper</a>]
			      [<a href="https://github.com/Koorye/DePT">Code</a>]
			    </p>

			    <p>
			      Overcoming the base-new tradeofff (BNT) problem for existing prompt tuning methods.
			    </p>
			  </div>
			</div>

			<!-- Highlight 5 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/JimZAI/MODE-OOD">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjitip.png"
			             style="float: right;" width="350px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">From Global to Local: Multi-scale Out-of-distribution Detection</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Heng Tao Shen<br>
			      IEEE Transactions on Image Processing (<strong>TIP</strong>), 2023<br>
			      [<a href="https://arxiv.org/pdf/2308.10239">Paper</a>]
			      [<a href="https://github.com/JimZAI/MODE-OOD">Code</a>]
			    </p>

			    <p>
			      Leveraging both global visual information and local region details of images to maximally benefit OOD detection.
			    </p>
			  </div>
			</div>

			<!-- Highlight 6 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/JimZAI/DETA">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjiiccv.png"
			             style="float: left;" width="330px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">DETA: Denoised Task Adaptation for Few-shot Learning</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>, Lianli Gao, Xu Luo, Heng Tao Shen, Jingkuan Song<br>
			      IEEE International Conference on Computer Vision (<strong>ICCV</strong>), 2023<br>
			      [<a href="https://arxiv.org/pdf/2303.06315">Paper</a>]
			      [<a href="https://github.com/JimZAI/DETA">Code</a>]
			    </p>

			    <p>
			      Tacking both the X-noise (i.e., image noise) and the Y-noise (i.e., label noise) in a unified framework for test-time few-shot tasks.
			    </p>
			  </div>
			</div>

			<!-- Highlight 7 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/Frankluox/CloserLookAgainFewShot">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjiicml.jpeg"
			             style="float: right;" width="350px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">A Closer Look at Few-shot Classification Again</strong></h5>

			    <p>
			      Xu Luo*, Hao Wu*, <strong>Ji Zhang</strong>, Lianli Gao, Jing Xu, Jingkuan Song<br>
			      International Conference on Machine Learning (<strong>ICML</strong>), 2023<br>
			      [<a href="https://arxiv.org/pdf/2301.12246">Paper</a>]
			      [<a href="https://github.com/Frankluox/CloserLookAgainFewShot">Code</a>]
			    </p>

			    <p>
			      Empirically proving the disentanglement of training and test-time adaptation algorithms in few-shot classification.
			    </p>
			  </div>
			</div>

			<!-- Highlight 8 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/JimZAI/SET-RCL">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjisetrcl.png"
			             style="float: left;" width="330px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">Free-lunch for Cross-domain Few-shot learning: Style-aware Episodic Training with Robust Contrastive Learning</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>, Jingkuan Song, Lianli Gao, Heng Tao Shen<br>
			      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022<br>
			      [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547835">Paper</a>]
			      [<a href="https://github.com/JimZAI/SET-RCL">Code</a>]
			    </p>

			    <p>
			      Addressing the side-effect of style-shift between tasks from source and target domains.
			    </p>
			  </div>
			</div>

			<!-- Highlight 9 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/JimZAI/SepMeta">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjitcsvt2.png"
			             style="float: right;" width="350px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">Progressive Meta-learning with Curriculum</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>, Jingkuan Song, Lianli Gao, Ye Liu, Heng Tao Shen<br>
			      IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2022<br>
			      [<a href="https://ieeexplore.ieee.org/abstract/document/9745972/">Paper</a>]
			      [<a href="https://github.com/JimZAI/SepMeta">Code</a>]
			    </p>

			    <p>
			      An extended version the ACM MM'21 paper, where the curriculum is effectively integrated as a regularization term into the objective so that the meta-learner can measure the hardness of tasks adaptively.
			    </p>
			  </div>
			</div>

			<!-- Highlight 10 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			  <div class="boxed">
			    <p>
			      <a href="https://github.com/JimZAI/CubMeta">
			        <img border="1px" hspace="10" vspace="10"
			             src="./files/JiZhang/zhangjicubmeta.png"
			             style="float: left;" width="330px">
			      </a>
			    </p>

			    <h5><strong style="color: black;">Curriculum-based Meta-learning</strong></h5>

			    <p>
			      <strong>Ji Zhang</strong>, Jingkuan Song, Yazhou Yao, Lianli Gao<br>
			      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2021<br>
			      [<a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475335">Paper</a>]
			      [<a href="https://github.com/JimZAI/CubMeta">Code</a>]
			    </p>

			    <p>
			      Progressively improving the meta-learner by performing episodic training on simulating tasks from easy to hard, i.e., in a curriculum learning manner.
			    </p>
			  </div>
			</div>
		</div>

		 
				    
				    
		<div class="content">
			<h5 class="text-primary" id="publications">Publications</h5>

			<ul>
				<li> <b> InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning </b> &nbsp <a href="https://arxiv.org/pdf/2505.13888">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Shihan Wu, Xu Luo, Hao Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song <br>IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2026 <br><br></li>
				<li> <b> Policy Contrastive Decoding for Robotic Foundation Models </b> &nbsp <a href="https://arxiv.org/pdf/2505.13255">[pdf]</a> &nbsp <br>Shihan Wu, Xu Luo, <b>Ji Zhang</b>, Junlin Xie, Jingkuan Song, Heng Tao Shen, Lianli Gao <br>International Conference on Learning Representations (<b>ICLR</b>), 2026 <br><br></li>
				<li> <b> A Closer Look at Conditional Prompt Tuning for Vision-Language Models </b> &nbsp <a href="https://arxiv.org/pdf/2506.23856">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Shihan Wu, Lianli Gao, Jingkuan Song, Nicu Sebe, Heng Tao Shen <br>International Journal of Computer Vision (<b>IJCV</b>) <br><br></li>
				<li> <b> In-Context Adaptation for Generalizable Imitation Learning </b> &nbsp <a href="https://openreview.net/pdf?id=mBHHyZrWE1">[pdf]</a> &nbsp <br>Junlin Xie, Xu Luo, Hao Wu, <b>Ji Zhang</b>, Youguang Xing, Lianli Gao, Jingkuan Song <br>CoRL Workshop RemembeRL, 2025 <br><br></li>
				<li> <b> Reliable Few-shot Learning under Dual Noises </b> &nbsp <a href="https://arxiv.org/pdf/2506.16330">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Lianli Gao, Nicu Sebe, Heng Tao Shen <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>) <br><br></li>
				<li> <b> Modeling Temporal Dependencies within the Target for Long-Term Time Series Forecasting </b> &nbsp <a href="https://arxiv.org/pdf/2406.04777">[pdf]</a> &nbsp <br>Qi Xiong, Kai Tang, Minbo Ma, <b>Ji Zhang</b>, Jie Xu, Tianrui Li <br>IEEE Transactions on Knowledge and Data Engineering (<b>TKDE</b>) <br><br></li>
				<li> <b> Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves </b> &nbsp <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Skip_Tuning_Pre-trained_Vision-Language_Models_are_Effective_and_Efficient_Adapters_CVPR_2025_paper.pdf">[pdf]</a> &nbsp <br>Shihan Wu, <b>Ji Zhang</b>, Pengpeng Zeng, Lianli Gao, Jingkuan Song, Heng Tao Shen <br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025 <br><br></li>
				<li> <b> Effective and Efficient Few-shot Fine-tuning for Vision Transformers </b> &nbsp <a href="https://drive.google.com/file/d/1kh_ymmQSDccEgZk3mhm5ovkL5_24upTz/view">[pdf]</a> &nbsp <br>Junjie Yang, Hao Wu, <b>Ji Zhang</b>, Lianli Gao, Jingkuan Song <br>IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2024 <br><br></li>
				<li> <b> DePT: Decoupled Prompt Tuning </b> &nbsp <a href="http://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_DePT_Decoupled_Prompt_Tuning_CVPR_2024_paper.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Shihan Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song <br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024 <br><br></li>
				<li> <b> From Global to Local: Multi-scale Out-of-distribution Detection </b> &nbsp <a href="https://arxiv.org/pdf/2308.10239">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Heng Tao Shen <br>IEEE Transactions on Image Processing (<b>TIP</b>) <br><br></li>
				<li> <b> DETA: Denoised Task Adaptation for Few-Shot Learning </b> &nbsp <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Lianli Gao, Xu Luo, Heng Tao Shen, Jingkuan Song <br>IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023 <br><br></li>
				<li> <b> A Closer Look at Few-shot Classification Again </b> &nbsp <a href="https://proceedings.mlr.press/v202/luo23e/luo23e.pdf">[pdf]</a> &nbsp <br>Xu Luo, Hao Wu, <b>Ji Zhang</b>, Lianli Gao, Jing Xu, Jingkuan Song <br>International Conference on Machine Learning (<b>ICML</b>), 2023 <br><br></li>
				<li> <b> Class Gradient Projection for Continual Learning </b> &nbsp <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548054">[pdf]</a> &nbsp <br>Cheng Chen, <b>Ji Zhang</b>, Jingkuan Song, Lianli Gao <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2022 <br><br></li>
				<li> <b> Free-lunch for Cross-domain Few-shot learning: Style-aware Episodic Training with Robust Contrastive Learning </b> &nbsp <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547835">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Lianli Gao, Heng Tao Shen <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2022 <br><br></li>
				<li> <b> Progressive Meta-learning with Curriculum </b> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Lianli Gao, Ye Liu, Heng Tao Shen <br>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>) <br><br></li>
				<li> <b> Curriculum-based Meta-learning </b> &nbsp <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475335">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Yazhou Yao, Lianli Gao <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2021 <br><br></li>
				<li> <b> Co-adjustment Learning for Co-clustering </b> &nbsp <a href="https://www.researchgate.net/profile/Hongjun-Wang-14/publication/348586746_Co-Adjustment_Learning_for_Co-Clustering/links/636cf3cb54eb5f547cbe9b1d/Co-Adjustment-Learning-for-Co-Clustering.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Hongjun Wang, Shudong Huang, Tianrun Li, Peng Jin, Ping Deng, Qigang Zhao <br>Cognitive Computation <br><br></li>
				<li> <b> Improved Gaussian–Bernoulli Restricted Boltzmann Machine for Learning Discriminative Representations </b> &nbsp <a href="https://www.academia.edu/download/98135362/j.knosys.2019.10491120230202-1-1h5owmv.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Hongjun Wang, Jielei Chu, Shudong Huang, Tianrui Li, Qigang Zhao <br>Knowledge-Based Systems <br><br></li>
				<li> <b> A Factor Graph Model for Unsupervised Feature Selection </b> &nbsp <a href="http://miai.ha.edu.cn/Essays/7Feature%20selection%20techniques/A%20factor%20graph%20model%20for%20unsupervised%20feature%20selection.pdf">[pdf]</a> &nbsp <br>Hongjun Wang, Yinghui Zhang, <b>Ji Zhang</b>, Tianrui Li, Lingxi Peng <br>Information Sciences <br><br></li>
			</ul>
		</div>

		<div class="content" id="teach">
			<h5 class="text-primary">Teaching</h5>
			<ul>
			  <li><strong>Instructor</strong>, COMP130124, Computer Vision, Fudan University, For Undergraduate Students, Fall 2021, 2022, 2023, 2024, 2025</li>
			  <li><strong>Instructor</strong>, COMP620028, Information Retrieval, Fudan University, For Graduate Students, Fall 2020, 2021, 2022, 2023, 2024</li>
			  <li><strong>Instructor</strong>, Advanced Media Computing, Fudan University, For Senior Undergraduate and Graduate Students, Summer Semester 2022</li>
			  <li><strong>Instructor</strong>, Frontiers of Computer Vision, For Senior Undergraduate and Graduate Students, Summer Semester 2022</li>
			</ul>
		</div>		

		<div class="content">
			<h5 class="text-primary">Academic Services</h5>
				<ul>
				  <li><strong>Associate Editor</strong>: IEEE TMM, ACM TOMM, Neurocomputing</li>
				  <li><strong>Editor</strong>: ACM SIGMM Records</li>
				  <li><strong>Technical Committee Member</strong>: IEEE-CAS Multimedia Systems & Applications (2021-2025)</li>
				  <li><strong>Conference Area Chair (AC)</strong>: 
				    <ul>
				      <li>ACM Multimedia (2020, 2024)</li>
				      <li>ACL (2023)</li>
				    </ul>
				  </li>
				  <li><strong>Senior Program Chair</strong>: AAAI (2023, 2024, 2025)</li>
				  <li><strong>Conference Organizer</strong>: 
				    <ul>
				      <li>ACM Multimedia 2025 (Demo Co-Chair)</li>
				      <li>Multimedia Modeling 2025 (Program Co-Chair)</li>
				      <li>ACM Multimedia Asia 2025 (Publicity Chair)</li>   
				      <li>ACM Multimedia 2021 (Registration Chair)</li>
				      <li>ACM ICMR 2022 (Publicity Chair)</li>
				      <li>ICME 2022 (Special Session Chair)</li>
				      <li>ACM Multimedia Asia 2023 (Publicity Chair)</li>
				    </ul>
				  </li>
				  <li><strong>Conference Reviewer</strong>: ACM MM, ICLR, CVPR, ICCV, ECCV, etc.</li>
				  <li><strong>Journal Reviewer</strong>: TPAMI, TIP, TKDE, TMM, TOMM, TCSVT, etc.</li>
				</ul>

		</div>


	
		<div class="content" id="team">
		    <h5 class="text-primary" id="team_time">Team Time</h5> 
		    <div class="projects" style="margin-left: 1em; margin-right: 1em">


			<!-- 如何加画廊？ -->
				<!-- 1： 设置资源 imagesBox{id} currentIndexBox{id}-->
				<!-- 2： 设置切换逻辑 changeImage(boxId, direction) -->
				<!-- 3： 设置控件 id gallery-link-{id}  gallery-image-{id}  -->

			<script>
			    // Image list
			    // 2024 dec
			    const imagesBox1 = [
			        { src: "./files/Christmas2024/1.jpg", link: "./files/Christmas2024/1.jpg" },
			        { src: "./files/Christmas2024/2.jpg", link: "./files/Christmas2024/2.jpg" },
			        { src: "./files/Christmas2024/3.jpg", link: "./files/Christmas2024/3.jpg" },
					{ src: "./files/Christmas2024/4.jpg", link: "./files/Christmas2024/4.jpg" }
			    ];
			    let currentIndexBox1 = 0;

			    // 2025 may
			    const imagesBox2 = [
			        { src: "./files/2025may/p1.jpg", link: "./files/2025may/p1.jpg" },
			        { src: "./files/2025may/p2.jpg", link: "./files/2025may/p2.jpg" },
			        { src: "./files/2025may/p3.jpg", link: "./files/2025may/p3.jpg" },
					{ src: "./files/2025may/p4.jpg", link: "./files/2025may/p4.jpg" }
			    ];
			    let currentIndexBox2 = 0;


				// 2025 Christmas
			    const imagesBox3 = [
			        { src: "./files/files2025Christmas/1.jpg", link: "./files/files2025Christmas/1.jpg" },
			        { src: "./files/files2025Christmas/3.jpg", link: "./files/files2025Christmas/3.jpg" },
					{ src: "./files/files2025Christmas/5.jpg", link: "./files/files2025Christmas/5.jpg" },
					{ src: "./files/files2025Christmas/4.jpg", link: "./files/files2025Christmas/4.jpg" }
			    ];
			    let currentIndexBox3 = 0;
			
			    // Change image function
			    function changeImage(boxId, direction) {
			        let images, currentIndex;
			
			        // Determine which gallery to modify
			        if (boxId === 1) {
			            images = imagesBox1;
			            currentIndex = currentIndexBox1;
			        }
					if (boxId === 2) {
			            images = imagesBox2;
			            currentIndex = currentIndexBox2;
			        }
					if (boxId === 3) {
			            images = imagesBox3;
			            currentIndex = currentIndexBox3;
			        }
			
			        // Update the index
			        currentIndex += direction;
			
			        // Loop around if out of bounds
			        if (currentIndex < 0) {
			            currentIndex = images.length - 1;
			        } else if (currentIndex >= images.length) {
			            currentIndex = 0;
			        }
			
			        // Update the image and link
			        document.getElementById(`gallery-image-${boxId}`).src = images[currentIndex].src;
			        document.getElementById(`gallery-link-${boxId}`).href = images[currentIndex].link;
			
			        // Save the updated index
			        if (boxId === 1) {
			            currentIndexBox1 = currentIndex;
			        }
					if (boxId === 2) {
			            currentIndexBox2 = currentIndex;
			        }
					if (boxId === 3) {
			            currentIndexBox3 = currentIndex;
			        }
			    }
			</script>
				

			<!-- box -2 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			    <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
			
			        <!-- Gallery Section -->
			        <div class="gallery" 
			            style="position: relative; float: right; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc; width: 320px; height: 260px;">
			            <button class="prev" 
			                style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(3, -1)">&#10094;</button>
			
			            <!-- Image with link -->
			            <a id="gallery-link-3" href="./files/files2025Christmas/1.jpg">
			                <img id="gallery-image-3" src="./files/files2025Christmas/1.jpg" 
			                     alt="Christmas2025" 
			                     style="width: 100%; height: 100%; object-fit: cover;">
			            </a>
			
			            <button class="next" 
			                style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(3, 1)">&#10095;</button> 
			        </div>
			
			        <!-- Text Section -->
			        <h5><strong>Merry Christmas 2025!</strong></h5>
			        <p>2025-Dec</p> <br>
			        <p>We are celebrating Christmas in Hainan this year. It’s an island famous for its beaches, Wenchang chicken, and seafood.</p>
					
			    </div>
			</div>
			<!-- end box -2 -->

				

			<!-- box -1 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			    <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
			
			        <!-- Gallery Section -->
			        <div class="gallery" 
			            style="position: relative; float: left; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc; width: 320px; height: 260px;">
			
			            <!-- Image with link -->
						
			            <a href="./files/2025sep/25_sep_2.jpg.jpg">
			                <img src="./files/2025sep/25_sep_2.jpg" 
			                     alt="2025 Fall" 
			                     style="width: 100%; height: 100%; object-fit: cover;">
			            </a>
			
			        </div>
			
			        <!-- Text Section -->
			        <h5><strong>New semester!</strong></h5>
			        <p>2025-Sep</p> <br>
			        <p>We welcome new team members: Yuhang Zhou, Fei Li, Jiajia Shi, Ziyao Tang, Zihao Cai, Zixiang Meng, Jianggang Zhu.</p>
			    </div>
			</div>
			<!-- end box -1 -->

			
			<!-- box 0 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			    <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
			
			        <!-- Gallery Section -->
			        <div class="gallery" 
			            style="position: relative; float: right; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc; width: 320px; height: 260px;">
			            <button class="prev" 
			                style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(2, -1)">&#10094;</button>
			
			            <!-- Image with link -->
			            <a id="gallery-link-2" href="./files/2025may/p1.jpg">
			                <img id="gallery-image-2" src="./files/2025may/p1.jpg" 
			                     alt="Team Christmas2024" 
			                     style="width: 100%; height: 100%; object-fit: cover;">
			            </a>
			
			            <button class="next" 
			                style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(2, 1)">&#10095;</button>
			        </div>
			
			        <!-- Text Section -->
			        <h5><strong>Farewell, class of 2025</strong></h5>
			        <p>2025-May</p> <br>
			        <p>Two PhD students and three master's students graduated this year. We spent a precious time with them, having a barbecue and dancing around the bonfire.</p>
			    </div>
			</div>
			<!-- end box 0 -->
			    


			<!-- box 1 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			    <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
			
			        <!-- Gallery Section -->
			        <div class="gallery" 
			            style="position: relative; float: left; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc; width: 320px; height: 260px;">
			            <button class="prev" 
			                style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(1, -1)">&#10094;</button>
			
			            <!-- Image with link -->
			            <a id="gallery-link-1" href="./files/Christmas2024/1.jpg">
			                <img id="gallery-image-1" src="./files/Christmas2024/1.jpg" 
			                     alt="Team Christmas2024" 
			                     style="width: 100%; height: 100%; object-fit: cover;">
			            </a>
			
			            <button class="next" 
			                style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(1, 1)">&#10095;</button>
			        </div>
			
			        <!-- Text Section -->
			        <h5><strong>Merry Christmas 2024!</strong></h5>
			        <p>2024-December</p> <br>
			        <p>We celebrate Christmas at the Anji Resort, enjoying hot springs, gourmet food, karaoke, and skiing. A heartfelt thanks to Yue Yu, Jiayu Wang, Pinye Chen, Xueqiao Wang, Junhao Xu, and Xinghan Li for their hard work in securing the activity funds that made this unforgettable experience possible!</p>
			    </div>
			</div>
			<!-- end box 1 -->

			<!-- box 2-->
			<!-- <div class="projects" style="margin-left: 1em; margin-right: 1em">
		        <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
		            <p>
		                <a href="./files/team_2024_freshman.jpg">
		                    <img src="./files/team_2024_freshman.jpg" 
		                         style="float: right; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc;" 
		                         height="260px" 
		                         alt="Team 2024 Freshman">
		                </a>
		            </p>
		
		            <h5><strong>Welcome new team members!</strong></h5>
		            <p>2024-9-1</p> <br>
		            <p>This year, we welcome new team members: Jiarui Yang, Chao Gong, Yian Li, Xinghan Li, Xueqiao Wang, Jianrong Yan, Tianxiao Xu, Shijie Zhou, and Xiaoyu Chen.</p>
		        </div>
			</div> -->


			<!-- box 3-->
			<!-- <div class="projects" style="margin-left: 1em; margin-right: 1em">
		        <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
		            <p>
		                <a href="./files/team_2024_graduate_1.jpg">
		                    <img src="./files/team_2024_graduate_1.jpg" 
		                         style="float: left; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc;" 
		                         width="380px" 
		                         alt="Farewell to the Class of 2024">
		                </a>
		            </p>
		
		            <h5><strong>Farewell to the Class of 2024!</strong></h5>
		            <p>2024-June</p> <br>
		            <p>This year, we have two doctoral graduates, Zhipeng Wei and Tianwen Qian, along with seven master's graduates: Zixuan Su, Yuehao Yin, Huiyan Qi, Yanqi Wu, Yue Yu, Wenzhuo Xu, and Yiqiang Lv. We wish them all the best in pursuing their dreams~</p>
		        </div>
			</div> -->
			    
		</div>


	


		<div class="content">
			
			<h5 class="text-primary">Group Members</h5>
		
			<strong>PhD Students:</strong>
			<ul>
			  <li>Feng Han (September 2023 – present) (Transfer from Master’s to PhD program) </li>
		      <li>Jiayu Wang (September 2023 – present) (Transfer from Master’s to PhD program) </li>
			  <li>Jianggang Zhu (September 2025 – present) </li>
			  <li>Zixiang Meng (September 2025 – present) </li>
			  <li>Jiarui Yang (September 2024 – present) <a href="https://flyfaerss.github.io/" target="_blank">homepage</a> </li>
			  <li>Yue Yu (September 2024 – present)</li>
			  <li>Guoshan Liu (September 2024 – present)</li>
			  <li>Yang Jiao (September 2021 – present) <a href="https://sxjyjay.github.io/" target="_blank">homepage</a> </li>
			  <li>Pengkun Jiao (September 2021 – present) <a href="https://pengkun-jiao.github.io/" target="_blank">homepage</a></li>
			  
			</ul>
			
			<strong>Master Students:</strong>
			<ul>
				<li> Fei Li, (September 2025 – present) </li>
				<li> Jiajia Shi, (September 2025 – present) </li>
				<li> Zihao Cai, (September 2025 – present) </li>
				<li> Ziyao Tang, (September 2025 – present) </li>
				<li> Yuhang Zhou, (September 2025 – present) </li>
				<li> Yuyan Chen, (September 2025 – present) </li>
				<li> Chao Gong, (September 2024 – present) </li>
				<li> Yian Li, (September 2024 – present) </li>
				<li> Xinghan Li, (September 2024 – present) </li>
				<li> Xueqiao Wang, (September 2024 – present) </li>
				<li> Jianrong Yan, (September 2024 – present) </li>
				<li> Tianxiao Xu, (September 2024 – present) </li>
				<li> Shijie Zhou, (September 2024 – present) </li>
				<li> Xiaoyu Chen, (September 2024 – present) </li>
				<li> Ziyi Gao, (September 2023 – present) </li>
				<li> Junhao Xu, (September 2023 – present) </li>
				<li> Pinye Chen, (September 2023 – present) </li>
				<li> Xinlan Wu, (September 2023 – present) </li>
			</ul>
				

		</div>

		<div class="content">
			<h5 class="text-primary">Former Members</h5>
				<ul>
					<li> <a href="https://scholar.google.com.hk/citations?user=M6CSZVsAAAAJ&hl=zh-CN" target="_blank">Xue Song</a> (Ph.D. student): September 2021 - July 2025, now at <a>Huawei (Singapore)</a>  <br> - <i> Thesis title: Controllable Visual Content Generation & Editing </i> 
					<li> <a href="https://scholar.google.com/citations?user=y01ICTAAAAAJ&hl=zh-CN" target="_blank">Kai Chen</a> (Ph.D. student): September 2020 - July 2025, now at <a>ByteDance</a>  <br> - <i> Thesis title: Adversarial Robustness in Video Recognition Models </i> 
					<li> <a href="https://zhipeng-wei.github.io" target="_blank">Zhipeng Wei</a> (Ph.D. student): September 2021 - June 2024, now at <a>UC Berkeley</a> as Postdoc researcher <br> - <i> Thesis title: Adversarial Robustness Evaluation for Deep Visual Models </i> 
					<li> <a href="https://qiantianwen.github.io" target="_blank">Tianwen Qian</a> (Ph.D. student): September 2019 - June 2024, now at <a href="https://www.ecnu.edu.cn/" target="_blank">ECNU</a> as Pre-tenured Associate Professor <br> - <i> Thesis title: Multi-modal Visual Question Answering </i> 
					<li> <a href="https://ccds.fzu.edu.cn/info/1204/10297.htm" target="_blank">Linhai Zhuo</a> (Ph.D. student): September 2019 - June 2023, now at <a>Fuzhou University</a> as Lecturer <br> - <i> Thesis title: Few-shot Image Recognition with Knowledge Transfer </i>  
					<li> Yinxuan Gui (Master Student), September 2022 – July 2025, Now at <a>Singapore Management University for PhD degree </a>
				    <li> Haoxiang Chen (Master Student), September 2022 – Jan 2026 </li>
				    <li> Jiacheng Zhang (Master Student), September 2022 – July 2025, Now at <a>Hetao for PhD Degree</a>
				    <li> Wentao Tian (Master Student), September 2022 – July 2025, Now at <a>Shopee</a>
					<li> Zixuan Su (Master Student): September 2021 - January 2024, Now at <a>Tencent</a>
					<li> Yuehao Yin (Master Student): September 2021 - January 2024 
					<li> Huiyan Qi (Master Student): September 2021 - January 2024, now at <a>SMU</a> as Research Associate
					<li> Yanqi Wu (Master Student): September 2021 - June 2024, Now at <a>Papal</a>. 
					<li> Yue Yu (Master Student): September 2021 - June 2024, now pursuing PhD degree at Fudan
					<li> WenZhuo Xu (Master Student): September 2021 - June 2024, now at <a>360</a>
					<li> Yiqiang Lv (Master Student): September 2021 - June 2024, now at <a>Pinduoduo</a>
					<li> Jianggang Zhu (Master Student): September 2020 - January 2023，now rejoined the team for PhD studies.
					<li> Fan Luo(Master Student): September 2020 - January 2023, now at <a>Century Frontier Asset Management</a>
					<li> Xueqing Zhou (Master Student): September 2019 - June 2024, now at <a>Antgroup </a>
					<li> Jixiang Gao (Master Student): September 2019 - January 2022, now at <a>Antgroup</a>
					<li> Jianlong Wu(Master Student): September 2019 - January 2022, now <a>running a startup company</a> 
					<li> Jinmian Cai(Master Student): September 2019 - January 2022,now at <a>Tencent</a> 
					<li> Tao Sha (Master Student): September 2019 - January 2022, now at <a>Ctrip</a>

				</ul>
		</div>
			
		<div class="content">
			<h5 class="text-primary">Miscellaneous</h5>


			<p>When I have spare time, I enjoy cooking. </p>

			<p>
			</p>
		</div>
		Webpage template borrowed from Prof. <a href="https://cocoxu.github.io/#advise">Wei Xu</a>.

	
</body></html>
