<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta content="IE=edge" http-equiv="X-UA-Compatible">
	<meta content="width=840, initial-scale=1.0" name="viewport">
	<meta content="Ji Zhang" name="author">
	<meta content="Homepage" name="description">

	<style>
	        strong {
	            color: #1772d0;
	        }
			.boxed::after {
				content: "";
				display: block;
				clear: both;
			}
			.projects .boxed img {
				max-width: 100%;
				height: auto;
			}
	    </style>

	<title>Ji Zhang</title>
	<link rel="shortcut icon" href="https://www.ic.gatech.edu/sites/all/themes/coc_sub_theme/favicon.ico" type="image/vnd.microsoft.icon">
	<!-- Bootstrap core CSS -->
	<link href="./files/bootstrap.min.css" rel="stylesheet">
	<!-- Bootstrap theme -->
	<link href="./files/bootstrap-theme.min.css" rel="stylesheet">
	<!-- Bootstrap icon -->
	<link href="./files/bootstrap.icon-large.min.css" rel="stylesheet">
	<!-- Custom styles for this template -->
	<link href="./files/theme.css" rel="stylesheet">
	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<link rel="stylesheet" href="./files/font-awesome.min.css">

	<!-- 在这里添加自定义链接样式 -->
	<style>
			/* 全局链接样式 */
			a {
				color: #1772d0;
				text-decoration: none;
			}
			
			a:hover, a:focus {
				color: #f09228;
				text-decoration: none;
			}
			
			a:visited, a:active {
				color: #1772d0;
			}
		</style>
	
	<!--[if lt IE 9]>
	  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
	  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
	<![endif]-->
<script src="chrome-extension://njgehaondchbmjmajphnhlojfnbfokng/js/contentScripts/dom.js"></script></head>

<body>
   <script type="text/javascript" async="" src="./files/ga.js"></script>
	<div class="container-narrow">
		<div class="title">

			<h4><strong>Ji Zhang</strong> &nbsp;&nbsp;&nbsp;&nbsp; 
			
			<img class="img-thumbnail-lizi" height="220" hspace="20" src="./files/JiZhang/jizhang_.jpg" style="float:right"> 
	
			</h4>
			Assistant Professor, Southwest Jiaotong University<br>
			<!-- <a href="https://scai.swjtu.edu.cn/">School of Computing and Artificial Intelligence</a> <br> -->
			<!-- <a href="https://www.swjtu.edu.cn/">Southwest Jiaotong University</a><br> -->
			<!-- <span class="glyphicon glyphicon-envelope"></span>&nbsp; <tt>jizhang@swjtu.edu.cn</tt><br> -->
			<!-- <a href="https://www.swjtu.edu.cn/">Southwest Jiaotong University</a><br> -->
			<a href="https://scholar.google.com/citations?user=F9dKrEwAAAAJ&hl=en">[Google Scholar]</a>
			<a href="https://github.com/JimZAI">[GitHub]</a><br>
			<b>Email</b>: jizhang.jim@gmail.com&nbsp;&nbsp;
			<b>WeChat</b>: Enjoy_Every_Episode
			
		    <br><br>
		    	<p>I am Ji Zhang (张继), an Assistant Professor in the School of Computing and Artificial Intelligence at Southwest Jiaotong University (SWJTU). I received my Ph.D. degree in 2024 from the School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), where I was very fortunate to be advised by Prof.  <a href="https://scholar.google.com/citations?user=F5Zy9V4AAAAJ&hl=en&oi=ao">Jingkuan Song</a> and Prof. <a href="https://scholar.google.com/citations?user=zsm2dpYAAAAJ&hl=en&oi=ao">Lianli Gao</a>.

		        <p>My research interests include, but are not limited to:</p>
			<ol>
			  <li><strong>Robot Learning</strong>: Developing robust learning algorithms that enable autonomous agents to acquire complex manipulation skills and interact seamlessly with physical environments.</li>
              <li><strong>Multimodel Learning</strong>: Leveraging large-scale multimodal pre-training to develop versatile models capable of cross-modal reasoning tasks.</li>
              <li><strong>Computer Vision</strong>: Tackling fundamental challenges in visual perception, including object recognition, scene understanding, and OOD detection.</li>
			</ol>
			<!-- <p>If you are also interested in related topics, please do not hesitate to reach out.</p> -->

			<!-- <br> -->
						
			<img src="./files/recruitment.png" width="20" alt="" style="border-style: none" align="center"> &nbsp; 
			<strong>Open Positions</strong>
			<be>
				<ul>
				  <li>There are 1-2 (resp. 3-4) openings for PhD (resp. Master) students with relevant research experience on Robot Learning, Multimodel Learning, and Computer Vision. Candidates are expected to have publications in top conferences (CVPR, ICCV, ECCV, NeurIPS, ICLR, ICML, RSS, ICRA, CoRL, etc.) or high-impact journals (TPAMI, IJCV, TIP, TMM, etc.). Qualified candidates are welcome to apply.</li>
				  <li>I am looking for 2-3 interns working on Robot Learning and Multimodel Learning. Please feel free to email me with your CV if you are interested.</li>
				  <!-- <li>Currently, there are no openings for PhD students starting in Fall 2026.</li> -->
				</ul>
			<!-- <br>  -->
			

		</div>

<div class="navbar navbar-default" role="navigation"> 
		 <div class="container">
        
				<div class="navbar-collapse">
				<ul class="nav navbar-nav">
					<li>
						<a href="https://jimzai.github.io/jimzai1.github.io/#research">Research</a>
					</li>

					<li>
						<a href="https://jimzai.github.io/jimzai1.github.io/#service">Services</a>
					</li>
					<!-- <li>
						<a href="https://jimzai.github.io/jimzai1.github.io/#teach">Teaching</a>
					</li>  -->
 <li>
						<a href="https://jimzai.github.io/jimzai1.github.io/#team">Team</a>
					</li>

					<li>
						<a href="https://jimzai.github.io/jingjing1.github.io/#research">Miscellaneous</a>
					</li>
				</ul>
			</div>
		</div> 
	
		 </div>  


		<div class="content">
			<h5 class="text-primary" id="news">What's New</h5>
			<!-- <ul class="news"> -->
			<ul>
				<li style="list-style: none">
				</li>

			<!-- <ul class="news"> -->
			    <li>[01/2026] Two papers about Robot Learning are accepted by ICRA'26. </li>
				<li>[12/2025] One paper about Robot Learning was accepted by ICLR'26.</li>
				<li>[12/2025] One paper about Multimodel Learning was accepted by IJCV</li>
				<li>[06/2025] One paper about Few-shot Learning was accepted by TPAMI.</li>
				<!-- <li>[04/2025] I have been invited to be a PC member for NeurIPS'25.</li> -->
				<!-- <li>[03/2025] I have been invited to be the PC members for ICCV'25 and ACM MM'25.</li> -->
				<li>[02/2025] One paper about Multimodel Learning was accepted by CVPR'25.</li>
				<!-- <li>[11/2024] I have been invited to be a PC member for CVPR'25.</li> -->
				<!-- <li>[08/2024] I have been invited to be a PC member for ICLR'25.</li> -->
				<li>[02/2024] One paper about Multimodel Learning was accepted by CVPR'24.</li>
				<li>[10/2023] One paper about OOD Detection was accepted by IEEE TIP.</li>
				<!-- <li>[10/2023] I'm awarded the "Graduate Chinese National Scholarship".</li> -->
				<li>[07/2023] One paper about Few-shot Learning was accepted by ICCV'23.</li>
				<li>[04/2023] Two papers about Few-shot Learning and Continue Learning are accepted by ACM MM'22.</li>
				<li>[06/2022] One paper about Few-shot Learning was accepted by ICML'23.</li>
				<li>[03/2022] One paper about Few-shot Learning was accepted by IEEE TCSVT.</li>
			  	<li>[06/2021] Our paper about Few-shot Learning was accepted by ACM MM'21.</li>
			</ul>		
		</div>
				    
		<div class="content">
			<h5 class="text-primary" id="publications">Selected Papers</h5>  &nbsp;&nbsp;&nbsp;&nbsp; (<sup><em>*</em></sup> Equal contribution, <sup><em>+</em></sup> Project Lead, <sup><em>#</em></sup> Corresponding author)
			<ul>
				<li> <b> InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning </b> &nbsp <a href="https://arxiv.org/pdf/2505.13888">[pdf]</a> &nbsp <br><b>Ji Zhang</b><sup><em>*</em></sup>, Shihan Wu<sup><em>*</em></sup>, Xu Luo, Hao Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song <br>IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2026 <br><br></li>
				<li> <b> Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation </b> &nbsp <a href="https://arxiv.org/pdf/2505.13888">[pdf]</a> &nbsp <br>Junhong Zhu<sup><em>*</em></sup>,<b>Ji Zhang</b><sup><em>*</em></sup><sup><em>+</em></sup>, Jingkuan Song, Lianli Gao, Heng Tao Shen <br>IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2026 <br><br></li>
				<li> <b> Policy Contrastive Decoding for Robotic Foundation Models </b> &nbsp <a href="https://arxiv.org/pdf/2505.13255">[pdf]</a> &nbsp <br>Shihan Wu, Xu Luo, <b>Ji Zhang</b><sup><em>#</em></sup>, Junlin Xie, Jingkuan Song, Heng Tao Shen, Lianli Gao <br>International Conference on Learning Representations (<b>ICLR</b>), 2026 <br><br></li>
				<li> <b> A Closer Look at Conditional Prompt Tuning for Vision-Language Models </b> &nbsp <a href="https://arxiv.org/pdf/2506.23856">[pdf]</a> &nbsp <br><b>Ji Zhang</b><sup><em>#</em></sup>, Shihan Wu, Lianli Gao, Jingkuan Song, Nicu Sebe, Heng Tao Shen <br>International Journal of Computer Vision (<b>IJCV</b>), 2026 <br><br></li>
				<li> <b> Reliable Few-shot Learning under Dual Noises </b> &nbsp <a href="https://arxiv.org/pdf/2506.16330">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Lianli Gao, Nicu Sebe, Heng Tao Shen <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2025 <br><br></li>
				<li> <b> Modeling Temporal Dependencies within the Target for Long-Term Time Series Forecasting </b> &nbsp <a href="https://arxiv.org/pdf/2406.04777">[pdf]</a> &nbsp <br>Qi Xiong, Kai Tang, Minbo Ma, <b>Ji Zhang</b>, Jie Xu, Tianrui Li <br>IEEE Transactions on Knowledge and Data Engineering (<b>TKDE</b>), 2025 <br><br></li>
				<li> <b> In-Context Adaptation for Generalizable Imitation Learning </b> &nbsp <a href="https://openreview.net/pdf?id=mBHHyZrWE1">[pdf]</a> &nbsp <br>Junlin Xie, Xu Luo, Hao Wu, <b>Ji Zhang</b>, Youguang Xing, Lianli Gao, Jingkuan Song <br>Conference on Robot Learning (<b>CoRL Workshop</b>), 2025 <br><br></li>
				<li> <b> Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves </b> &nbsp <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Skip_Tuning_Pre-trained_Vision-Language_Models_are_Effective_and_Efficient_Adapters_CVPR_2025_paper.pdf">[pdf]</a> &nbsp <br>Shihan Wu, <b>Ji Zhang</b><sup><em>#</em></sup>, Pengpeng Zeng, Lianli Gao, Jingkuan Song, Heng Tao Shen <br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025 <br><br></li>
				<!-- <li> <b> Effective and Efficient Few-shot Fine-tuning for Vision Transformers </b> &nbsp <a href="https://drive.google.com/file/d/1kh_ymmQSDccEgZk3mhm5ovkL5_24upTz/view">[pdf]</a> &nbsp <br>Junjie Yang, Hao Wu, <b>Ji Zhang</b>, Lianli Gao, Jingkuan Song <br>IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2024 <br><br></li> -->
				<li> <b> DePT: Decoupled Prompt Tuning </b> &nbsp <a href="http://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_DePT_Decoupled_Prompt_Tuning_CVPR_2024_paper.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b><sup><em>*</em></sup>, Shihan Wu<sup><em>*</em></sup>, Lianli Gao, Heng Tao Shen, Jingkuan Song <br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024 <br><br></li>
				<li> <b> From Global to Local: Multi-scale Out-of-distribution Detection </b> &nbsp <a href="https://arxiv.org/pdf/2308.10239">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Heng Tao Shen <br>IEEE Transactions on Image Processing (<b>TIP</b>), 2023 <br><br></li>
				<li> <b> DETA: Denoised Task Adaptation for Few-Shot Learning </b> &nbsp <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Lianli Gao, Xu Luo, Heng Tao Shen, Jingkuan Song <br>IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023 <br><br></li>
				<li> <b> A Closer Look at Few-shot Classification Again </b> &nbsp <a href="https://proceedings.mlr.press/v202/luo23e/luo23e.pdf">[pdf]</a> &nbsp <br>Xu Luo, Hao Wu, <b>Ji Zhang</b>, Lianli Gao, Jing Xu, Jingkuan Song <br>International Conference on Machine Learning (<b>ICML</b>), 2023 <br><br></li>
				<li> <b> Class Gradient Projection for Continual Learning </b> &nbsp <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548054">[pdf]</a> &nbsp <br>Cheng Chen, <b>Ji Zhang</b>, Jingkuan Song, Lianli Gao <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2022 <br><br></li>
				<li> <b> Progressive Meta-learning with Curriculum </b> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Lianli Gao, Ye Liu, Heng Tao Shen <br>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2022 <br><br></li>
				<li> <b> Free-lunch for Cross-domain Few-shot learning: Style-aware Episodic Training with Robust Contrastive Learning </b> &nbsp <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547835">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Lianli Gao, Heng Tao Shen <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2022 <br><br></li>
				<li> <b> Curriculum-based Meta-learning </b> &nbsp <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475335">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Jingkuan Song, Yazhou Yao, Lianli Gao <br>ACM International Conference on Multimedia (<b>ACM MM</b>), 2021 <br><br></li>
				<!-- <li> <b> Co-adjustment Learning for Co-clustering </b> &nbsp <a href="https://www.researchgate.net/profile/Hongjun-Wang-14/publication/348586746_Co-Adjustment_Learning_for_Co-Clustering/links/636cf3cb54eb5f547cbe9b1d/Co-Adjustment-Learning-for-Co-Clustering.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Hongjun Wang, Shudong Huang, Tianrun Li, Peng Jin, Ping Deng, Qigang Zhao <br>Cognitive Computation <br><br></li> -->
				<!-- <li> <b> Improved Gaussian–Bernoulli Restricted Boltzmann Machine for Learning Discriminative Representations </b> &nbsp <a href="https://www.academia.edu/download/98135362/j.knosys.2019.10491120230202-1-1h5owmv.pdf">[pdf]</a> &nbsp <br><b>Ji Zhang</b>, Hongjun Wang, Jielei Chu, Shudong Huang, Tianrui Li, Qigang Zhao <br>Knowledge-Based Systems <br><br></li> -->
				<!-- <li> <b> A Factor Graph Model for Unsupervised Feature Selection </b> &nbsp <a href="http://miai.ha.edu.cn/Essays/7Feature%20selection%20techniques/A%20factor%20graph%20model%20for%20unsupervised%20feature%20selection.pdf">[pdf]</a> &nbsp <br>Hongjun Wang, Yinghui Zhang, <b>Ji Zhang</b>, Tianrui Li, Lingxi Peng <br>Information Sciences <br><br></li> -->
			</ul>
		</div>

		<!-- <div class="content" id="teach">
			<h5 class="text-primary">Teaching</h5>
			<ul>
			  <li><strong>Instructor</strong>, COMP130124, Computer Vision, Fudan University, For Undergraduate Students, Fall 2021, 2022, 2023, 2024, 2025</li>
			  <li><strong>Instructor</strong>, COMP620028, Information Retrieval, Fudan University, For Graduate Students, Fall 2020, 2021, 2022, 2023, 2024</li>
			  <li><strong>Instructor</strong>, Advanced Media Computing, Fudan University, For Senior Undergraduate and Graduate Students, Summer Semester 2022</li>
			  <li><strong>Instructor</strong>, Frontiers of Computer Vision, For Senior Undergraduate and Graduate Students, Summer Semester 2022</li>
			</ul>
		</div>		 -->

		<div class="content", id="service">
			<h5 class="text-primary">Academic Services</h5>
				<ul>
				  <!-- <li><strong>Associate Editor</strong>: IEEE TMM, ACM TOMM, Neurocomputing</li>
				  <li><strong>Editor</strong>: ACM SIGMM Records</li>
				  <li><strong>Technical Committee Member</strong>: IEEE-CAS Multimedia Systems & Applications (2021-2025)</li>
				  <li><strong>Conference Area Chair (AC)</strong>: 
				    <ul>
				      <li>ACM Multimedia (2020, 2024)</li>
				      <li>ACL (2023)</li>
				    </ul>
				  </li>
				  <li><strong>Senior Program Chair</strong>: AAAI (2023, 2024, 2025)</li>
				  <li><strong>Conference Organizer</strong>: 
				    <ul>
				      <li>ACM Multimedia 2025 (Demo Co-Chair)</li> 
				      <li>Multimedia Modeling 2025 (Program Co-Chair)</li>
				      <li>ACM Multimedia Asia 2025 (Publicity Chair)</li>   
				      <li>ACM Multimedia 2021 (Registration Chair)</li>
				      <li>ACM ICMR 2022 (Publicity Chair)</li>
				      <li>ICME 2022 (Special Session Chair)</li>
				      <li>ACM Multimedia Asia 2023 (Publicity Chair)</li>
				    </ul>
				  </li> -->
				  <li><b>Conference Reviewer</b>: NeurIPS, ICLR, CVPR, ICCV, ECCV, ACL, ACM MM, AAAI, etc.</li>
				  <li><b>Journal Reviewer</b>: TPAMI, IJCV, TIP, TMM, TOMM, TCSVT, etc.</li>
				</ul>

		</div>


	
		<div class="content" id="team">
		    <h5 class="text-primary" id="team_time">Team Time</h5> 
		    <div class="projects" style="margin-left: 1em; margin-right: 1em">

				
			<!-- <script>
			    // Image list
			    // 2024 dec
			    const imagesBox1 = [
			        { src: "./files/Christmas2024/1.jpg", link: "./files/Christmas2024/1.jpg" },
			        { src: "./files/Christmas2024/2.jpg", link: "./files/Christmas2024/2.jpg" },
			        { src: "./files/Christmas2024/3.jpg", link: "./files/Christmas2024/3.jpg" },
					{ src: "./files/Christmas2024/4.jpg", link: "./files/Christmas2024/4.jpg" }
			    ];
			    let currentIndexBox1 = 0;

			    // 2025 may
			    const imagesBox2 = [
			        { src: "./files/2025may/p1.jpg", link: "./files/2025may/p1.jpg" },
			        { src: "./files/2025may/p2.jpg", link: "./files/2025may/p2.jpg" },
			        { src: "./files/2025may/p3.jpg", link: "./files/2025may/p3.jpg" },
					{ src: "./files/2025may/p4.jpg", link: "./files/2025may/p4.jpg" }
			    ];
			    let currentIndexBox2 = 0;


				// 2025 Christmas
			    const imagesBox3 = [
			        { src: "./files/files2025Christmas/1.jpg", link: "./files/files2025Christmas/1.jpg" },
			        { src: "./files/files2025Christmas/3.jpg", link: "./files/files2025Christmas/3.jpg" },
					{ src: "./files/files2025Christmas/5.jpg", link: "./files/files2025Christmas/5.jpg" },
					{ src: "./files/files2025Christmas/4.jpg", link: "./files/files2025Christmas/4.jpg" }
			    ];
			    let currentIndexBox3 = 0;
			
			    // Change image function
			    function changeImage(boxId, direction) {
			        let images, currentIndex;
			
			        // Determine which gallery to modify
			        if (boxId === 1) {
			            images = imagesBox1;
			            currentIndex = currentIndexBox1;
			        }
					if (boxId === 2) {
			            images = imagesBox2;
			            currentIndex = currentIndexBox2;
			        }
					if (boxId === 3) {
			            images = imagesBox3;
			            currentIndex = currentIndexBox3;
			        }
			
			        // Update the index
			        currentIndex += direction;
			
			        // Loop around if out of bounds
			        if (currentIndex < 0) {
			            currentIndex = images.length - 1;
			        } else if (currentIndex >= images.length) {
			            currentIndex = 0;
			        }
			
			        // Update the image and link
			        document.getElementById(`gallery-image-${boxId}`).src = images[currentIndex].src;
			        document.getElementById(`gallery-link-${boxId}`).href = images[currentIndex].link;
			
			        // Save the updated index
			        if (boxId === 1) {
			            currentIndexBox1 = currentIndex;
			        }
					if (boxId === 2) {
			            currentIndexBox2 = currentIndex;
			        }
					if (boxId === 3) {
			            currentIndexBox3 = currentIndex;
			        }
			    }
			</script> -->

			<!-- box -2 -->
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
			    <div class="boxed" style="border: 1px solid #DDDDDD; padding: 10px; width: auto; height: auto; overflow: hidden;">
			
			        <!-- Gallery Section -->
			        <div class="gallery" 
			            style="position: relative; float: right; margin-left: 10px; margin-right: 10px; border: 1px solid #ccc; width: 320px; height: 260px;">
			            <button class="prev" 
			                style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(3, -1)">&#10094;</button>
			
			            <!-- Image with link -->
			            <a id="gallery-link-3" href="./files/JiZhang/team2026.jpg">
			                <img id="gallery-image-3" src="./files/JiZhang/team2026.jpg" 
			                     alt="Christmas2025" 
			                     style="width: 100%; height: 100%; object-fit: cover;">
			            </a>
			
			            <button class="next" 
			                style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); background-color: rgba(0, 0, 0, 0.5); color: white; border: none; padding: 5px; cursor: pointer; z-index: 1;" 
			                onclick="changeImage(3, 1)">&#10095;</button> 
			        </div>
			
			        <!-- Text Section -->
			        <h5><b>2025 Annual Wrap-up Assembly</b></h5>
			        <p>01/2026</p> <br>
			        <p>We hosted our 2025 Annual Wrap-up Assembly! It was a wonderful opportunity to reflect on our scientific advancements and cherish the personal highlights of the past year. Various awards were presented to inspire our team to strive for excellence and make 2026 a year of abundant achievements.</p>
					
			    </div>
			</div>   
		</div>

		<div class="content">
			<h5 class="text-primary">Miscellaneous</h5>

			<p>When I have spare time, I enjoy hiking, running and cooking. </p>

			<p>
			</p>
		</div>
		This well-designed template was borrowed from Prof. <a href="https://cocoxu.github.io/#advise">Wei Xu</a>.

	
</body></html>
